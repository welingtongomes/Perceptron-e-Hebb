{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMLqrSrajpTEmjEOvy67Vz0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/welingtongomes/Perceptron-e-Hebb/blob/main/ExercicioAulaDoisRNA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Conjunto de treinamento\n",
        "training_data = np.array([\n",
        "    [-0.6508, 0.1097, 4.0009, -1],\n",
        "    [-1.4492, 0.8896, 4.4005, -1],\n",
        "    [2.0850, 0.6876, 12.0710, -1],\n",
        "    [0.2626, 1.1476, 7.7985, 1],\n",
        "    [0.6418, 1.0234, 7.0427, 1],\n",
        "    [0.2569, 0.6730, 8.3265, -1],\n",
        "    [1.1155, 0.6043, 7.4446, 1],\n",
        "    [0.0914, 0.3399, 7.0677, -1],\n",
        "    [0.0121, 0.5256, 4.6316, 1],\n",
        "    [-0.0429, 0.4660, 5.4323, 1],\n",
        "    [0.4340, 0.6870, 8.2287, -1],\n",
        "    [0.2735, 1.0287, 7.1934, 1],\n",
        "    [0.4839, 0.4851, 7.4850, -1],\n",
        "    [0.4089, -0.1267, 5.5019, -1],\n",
        "    [1.4391, 0.1614, 8.5843, -1],\n",
        "    [-0.9115, -0.1973, 2.1962, -1],\n",
        "    [0.3654, 1.0475, 7.4858, 1],\n",
        "    [0.2144, 0.7515, 7.1699, 1],\n",
        "    [0.2013, 1.0014, 6.5489, 1],\n",
        "    [0.6483, 0.2183, 5.8991, 1],\n",
        "    [-0.1147, 0.2242, 7.2435, -1],\n",
        "    [-0.7970, 0.8795, 3.8762, 1],\n",
        "    [-1.0625, 0.6366, 2.4707, 1],\n",
        "    [0.5307, 0.1285, 5.6883, 1],\n",
        "    [-1.2200, 0.7777, 1.7252, 1],\n",
        "    [0.3957, 0.1076, 5.6623, -1],\n",
        "    [-0.1013, 0.5989, 7.1812, -1],\n",
        "    [2.4482, 0.9455, 11.2095, 1],\n",
        "    [2.0149, 0.6192, 10.9263, -1],\n",
        "    [0.2012, 0.2611, 5.4631, 1],\n",
        "])\n",
        "\n",
        "def hebb(training_data, learning_rate, num_iterations, seed=None):\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    num_features = training_data.shape[1] - 1\n",
        "    weights = np.random.rand(num_features)\n",
        "\n",
        "    for _ in range(num_iterations):\n",
        "        for data in training_data:\n",
        "            inputs = data[:num_features]\n",
        "            desired_output = data[-1]\n",
        "            current_output = np.dot(weights, inputs)\n",
        "\n",
        "            if current_output * desired_output <= 0:\n",
        "                weights += learning_rate * desired_output * inputs\n",
        "\n",
        "    return weights\n",
        "\n",
        "learning_rate = 0.01\n",
        "num_iterations = 5\n",
        "\n",
        "# Armazenar os resultados dos 5 treinamentos em uma lista\n",
        "results = []\n",
        "\n",
        "for i in range(5):\n",
        "    seed = random.randint(0, 10000)\n",
        "    weights = hebb(training_data, learning_rate, num_iterations, seed)\n",
        "    results.append(weights)\n",
        "\n",
        "# Imprimir os resultados\n",
        "print(\"Treinamento | Pesos\")\n",
        "print(\"-------------|----------------------------------\")\n",
        "for i, weights in enumerate(results, start=1):\n",
        "    print(f\"{i: ^10d} | {weights}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGpykZE-PQ3G",
        "outputId": "bce06dfa-7979-456e-e432-e8096af6b181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinamento | Pesos\n",
            "-------------|----------------------------------\n",
            "    1      | [ 0.28004766  0.75279635 -0.11461811]\n",
            "    2      | [ 0.46917782  0.28196834 -0.13454006]\n",
            "    3      | [ 0.33740119  0.92287799 -0.14990585]\n",
            "    4      | [ 0.15741752  0.38708471 -0.10858797]\n",
            "    5      | [ 0.40618848  0.99863177 -0.1857071 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Conjunto de treinamento\n",
        "training_data = np.array([\n",
        "    [-0.6508, 0.1097, 4.0009, -1],\n",
        "    [-1.4492, 0.8896, 4.4005, -1],\n",
        "    [2.0850, 0.6876, 12.0710, -1],\n",
        "    [0.2626, 1.1476, 7.7985, 1],\n",
        "    [0.6418, 1.0234, 7.0427, 1],\n",
        "    [0.2569, 0.6730, 8.3265, -1],\n",
        "    [1.1155, 0.6043, 7.4446, 1],\n",
        "    [0.0914, 0.3399, 7.0677, -1],\n",
        "    [0.0121, 0.5256, 4.6316, 1],\n",
        "    [-0.0429, 0.4660, 5.4323, 1],\n",
        "    [0.4340, 0.6870, 8.2287, -1],\n",
        "    [0.2735, 1.0287, 7.1934, 1],\n",
        "    [0.4839, 0.4851, 7.4850, -1],\n",
        "    [0.4089, -0.1267, 5.5019, -1],\n",
        "    [1.4391, 0.1614, 8.5843, -1],\n",
        "    [-0.9115, -0.1973, 2.1962, -1],\n",
        "    [0.3654, 1.0475, 7.4858, 1],\n",
        "    [0.2144, 0.7515, 7.1699, 1],\n",
        "    [0.2013, 1.0014, 6.5489, 1],\n",
        "    [0.6483, 0.2183, 5.8991, 1],\n",
        "    [-0.1147, 0.2242, 7.2435, -1],\n",
        "    [-0.7970, 0.8795, 3.8762, 1],\n",
        "    [-1.0625, 0.6366, 2.4707, 1],\n",
        "    [0.5307, 0.1285, 5.6883, 1],\n",
        "    [-1.2200, 0.7777, 1.7252, 1],\n",
        "    [0.3957, 0.1076, 5.6623, -1],\n",
        "    [-0.1013, 0.5989, 7.1812, -1],\n",
        "    [2.4482, 0.9455, 11.2095, 1],\n",
        "    [2.0149, 0.6192, 10.9263, -1],\n",
        "    [0.2012, 0.2611, 5.4631, 1],\n",
        "])\n",
        "\n",
        "def hebb(training_data, learning_rate, num_iterations):\n",
        "    num_features = training_data.shape[1] - 1\n",
        "    weights = np.random.rand(num_features)\n",
        "    epochs = 0\n",
        "\n",
        "    for _ in range(num_iterations):\n",
        "        epochs += 1\n",
        "        errors = 0\n",
        "        for data in training_data:\n",
        "            inputs = data[:num_features]\n",
        "            desired_output = data[-1]\n",
        "            current_output = np.dot(weights, inputs)\n",
        "\n",
        "            if current_output * desired_output <= 0:\n",
        "                weights += learning_rate * desired_output * inputs\n",
        "                errors += 1\n",
        "\n",
        "        if errors == 0:\n",
        "            break\n",
        "\n",
        "    return weights, epochs\n",
        "\n",
        "learning_rate = 0.01\n",
        "num_iterations = 5\n",
        "\n",
        "# Mostrando os resultados na tabela\n",
        "print(\"Treinamento | Vetor de Pesos Inicial | Vetor de Pesos Final | Número de Épocas\")\n",
        "print(\"--------------------------------------------------------------------------------\")\n",
        "for i in range(5):\n",
        "    random.seed()\n",
        "    initial_weights = np.random.rand(4)\n",
        "    final_weights, epochs = hebb(training_data, learning_rate, num_iterations)\n",
        "    print(f\"{i+1:2d} {initial_weights} {final_weights} {epochs}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44mXxm9lWLLO",
        "outputId": "e9682953-9246-4a36-b1ff-09bd3fb74fb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinamento | Vetor de Pesos Inicial | Vetor de Pesos Final | Número de Épocas\n",
            "--------------------------------------------------------------------------------\n",
            " 1 [0.03622379 0.88447687 0.00991532 0.62412492] [ 0.27586669  0.7207521  -0.1329457 ] 5\n",
            " 2 [0.68668988 0.25165269 0.47994326 0.92247257] [ 0.42271167  0.77439159 -0.13616688] 5\n",
            " 3 [0.49332392 0.24802205 0.29379528 0.71921935] [ 0.56375807  0.46885863 -0.09875295] 5\n",
            " 4 [0.09455771 0.95627105 0.22374116 0.9252642 ] [ 0.31519063  0.1650816  -0.09785693] 5\n",
            " 5 [0.98117685 0.43751043 0.92921085 0.94181783] [ 0.43969629  0.2926091  -0.11589976] 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Conjunto de treinamento\n",
        "training_data = np.array([\n",
        "    [-0.6508, 0.1097, 4.0009, -1],\n",
        "    [-1.4492, 0.8896, 4.4005, -1],\n",
        "    [2.0850, 0.6876, 12.0710, -1],\n",
        "    [0.2626, 1.1476, 7.7985, 1],\n",
        "    [0.6418, 1.0234, 7.0427, 1],\n",
        "    [0.2569, 0.6730, 8.3265, -1],\n",
        "    [1.1155, 0.6043, 7.4446, 1],\n",
        "    [0.0914, 0.3399, 7.0677, -1],\n",
        "    [0.0121, 0.5256, 4.6316, 1],\n",
        "    [-0.0429, 0.4660, 5.4323, 1],\n",
        "    [0.4340, 0.6870, 8.2287, -1],\n",
        "    [0.2735, 1.0287, 7.1934, 1],\n",
        "    [0.4839, 0.4851, 7.4850, -1],\n",
        "    [0.4089, -0.1267, 5.5019, -1],\n",
        "    [1.4391, 0.1614, 8.5843, -1],\n",
        "    [-0.9115, -0.1973, 2.1962, -1],\n",
        "    [0.3654, 1.0475, 7.4858, 1],\n",
        "    [0.2144, 0.7515, 7.1699, 1],\n",
        "    [0.2013, 1.0014, 6.5489, 1],\n",
        "    [0.6483, 0.2183, 5.8991, 1],\n",
        "    [-0.1147, 0.2242, 7.2435, -1],\n",
        "    [-0.7970, 0.8795, 3.8762, 1],\n",
        "    [-1.0625, 0.6366, 2.4707, 1],\n",
        "    [0.5307, 0.1285, 5.6883, 1],\n",
        "    [-1.2200, 0.7777, 1.7252, 1],\n",
        "    [0.3957, 0.1076, 5.6623, -1],\n",
        "    [-0.1013, 0.5989, 7.1812, -1],\n",
        "    [2.4482, 0.9455, 11.2095, 1],\n",
        "    [2.0149, 0.6192, 10.9263, -1],\n",
        "    [0.2012, 0.2611, 5.4631, 1],\n",
        "])\n",
        "\n",
        "def hebb(training_data, learning_rate, num_iterations, seed=None):\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    num_features = training_data.shape[1] - 1\n",
        "    weights = np.random.rand(num_features)\n",
        "\n",
        "    for _ in range(num_iterations):\n",
        "        for data in training_data:\n",
        "            inputs = data[:num_features]\n",
        "            desired_output = data[-1]\n",
        "            current_output = np.dot(weights, inputs)\n",
        "\n",
        "            if current_output * desired_output <= 0:\n",
        "                weights += learning_rate * desired_output * inputs\n",
        "\n",
        "    return weights\n",
        "\n",
        "def classify(inputs, weights):\n",
        "    output = np.dot(inputs, weights)\n",
        "    return 1 if output >= 0 else -1\n",
        "\n",
        "# Novas amostras\n",
        "new_samples = np.array([\n",
        "    [-0.3565, 0.0620, 5.9891],\n",
        "    [-0.7842, 1.1267, 5.5912],\n",
        "    [0.3012, 0.5611, 5.8234],\n",
        "    [0.7757, 1.0648, 8.0677],\n",
        "    [0.1570, 0.8028, 6.3040],\n",
        "    [-0.7014, 1.0316, 3.6005],\n",
        "    [0.3748, 0.1536, 6.1537],\n",
        "    [-0.6920, 0.9404, 4.4058],\n",
        "    [-1.3970, 0.7141, 4.9263],\n",
        "    [-1.8842, -0.2805, 1.2548],\n",
        "])\n",
        "\n",
        "# Classificar as novas amostras usando cada conjunto de pesos treinados\n",
        "classification_results = []\n",
        "for weights in results:\n",
        "    sample_classifications = [classify(sample, weights) for sample in new_samples]\n",
        "    classification_results.append(sample_classifications)\n",
        "\n",
        "# Imprimir os resultados\n",
        "print(\" Amostra |\", \"  y(T1)   |\", \"  y(T2)   |\", \"  y(T3)   |\", \"  y(T4)   |\", \"  y(T5)\")\n",
        "print(\"---------|----------|----------|----------|----------|---------\")\n",
        "for i, sample in enumerate(new_samples, start=1):\n",
        "    print(f\"{i: ^8d}\", end=\"|\")\n",
        "    for j in range(5):\n",
        "        print(f\"{classification_results[j][i-1]: ^10d}\", end=\"|\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aK1ScnWHRCO2",
        "outputId": "d243493b-45e3-4781-b630-ebe8992b21ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Amostra |   y(T1)   |   y(T2)   |   y(T3)   |   y(T4)   |   y(T5)\n",
            "---------|----------|----------|----------|----------|---------\n",
            "   1    |    -1    |    -1    |    -1    |    -1    |    -1    |\n",
            "   2    |    -1    |    -1    |    -1    |    -1    |    -1    |\n",
            "   3    |    -1    |    -1    |    -1    |    -1    |    -1    |\n",
            "   4    |    1     |    -1    |    1     |    -1    |    -1    |\n",
            "   5    |    -1    |    -1    |    -1    |    -1    |    -1    |\n",
            "   6    |    1     |    -1    |    1     |    -1    |    1     |\n",
            "   7    |    -1    |    -1    |    -1    |    -1    |    -1    |\n",
            "   8    |    1     |    -1    |    -1    |    -1    |    -1    |\n",
            "   9    |    -1    |    -1    |    -1    |    -1    |    -1    |\n",
            "   10   |    -1    |    -1    |    -1    |    -1    |    -1    |\n"
          ]
        }
      ]
    }
  ]
}